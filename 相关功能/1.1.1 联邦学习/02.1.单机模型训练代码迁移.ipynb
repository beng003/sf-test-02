{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将单机模型训练代码迁移 SecretFlow 联邦学习训练代码教程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 引言\n",
    "### 背景\n",
    "随着数据隐私问题日益受到重视，并且实际业务场景的需求不断演变，联邦学习作为一种特殊的深度学习形式开始迅速兴起。它以一种创新的方式解决了传统集中式训练的数据隐私问题，能够在保护用户隐私的前提下，有效地训练机器学习模型。  \n",
    "那么假如现实的业务中已经有了单机模型，应该如何将它进行联邦化呢？为了易用性，我们的隐语在设计之初就希望能够以最低的成本来帮助用户迁移已有的单机模型到联邦模型。\n",
    "\n",
    "### 教程目标以及内容\n",
    "通过本教程的学习：\n",
    "1. 读者可以快速的将已有的单机模型正确的使用SecretFlow来进行联邦化。  \n",
    "2. 先通过单机模型完成模型开发，再进行联邦化适配，也是一个比较推荐的开发实践，可以提高联邦模型的开发效率。\n",
    "\n",
    "本教程将手把手的带你学习如何将已有的单机模型训练代码迁移到SecretFlow中进行联邦学习。\n",
    "1. 介绍迁移的整体流程\n",
    "2. 通过案例介绍在Tensorflow作为后端的迁移流程\n",
    "3. 通过案例介绍在Pytorch作为后端的迁移流程  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迁移的步骤\n",
    "\n",
    "基于 PyTorch 从单机模型到联邦学习模型，主要需要添加或修改以下几部分\n",
    "- 添加联邦学习中的参与方\n",
    "- 修改数据集的处理逻辑\n",
    "- 修改模型的继承类\n",
    "- 根据需要决定是否对 metric 、 optimizer 和 loss fuction 进行包装，并使用包装后的函数\n",
    "\n",
    "基于 TensorFlow 从单机模型到联邦学习模型，主要需要添加或修改以下几部分\n",
    "- 添加联邦学习中的参与方\n",
    "- 修改数据集的处理逻辑\n",
    "- 进行模型的封装\n",
    "\n",
    "得益于隐语的封装，使用者不需要自己进行大量的代码编写，只需要调用 Secretflow 中的函数，即可便捷完成模型的定义和使用等操作。  \n",
    "迁移完成后，不同后端不同的模型都使用一套API来进行`fit`,`predict`,`evaluate`等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前期数据准备\n",
    "相关文档可以参考相关IO文档\n",
    "\n",
    "下载数据集并解压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "import tempfile\n",
    "\n",
    "# # Create a temporary folder\n",
    "# _temp_dir = \"/home/beng003/python_project/sf-test/data\"\n",
    "\n",
    "# # Download file\n",
    "# url = \"https://secretflow-data.oss-accelerate.aliyuncs.com/datasets/tf_flowers/flower_photos.tgz\"\n",
    "# save_path = os.path.join(_temp_dir, \"flower_photos.tgz\")\n",
    "\n",
    "# response = requests.get(url)\n",
    "# with open(save_path, \"wb\") as f:\n",
    "#     f.write(response.content)\n",
    "\n",
    "# # Extract the file\n",
    "# extract_folder = os.path.join(_temp_dir, \"flower_photos\")\n",
    "# os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "# with tarfile.open(save_path, \"r:gz\") as tar:\n",
    "#     tar.extractall(path=extract_folder)\n",
    "\n",
    "# path_to_flower_dataset = extract_folder\n",
    "\n",
    "path_to_flower_dataset = (\n",
    "    \"/home/beng003/python_project/sf-test/data/datasets/flower_photos\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于PyTorch的迁移教程\n",
    "\n",
    "### 模型在 PyTorch 下的单机模型实现\n",
    "首先我们给出单机模式下，基于 PyTorch 定义和训练神经网络模型的过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# parameter\n",
    "batch_size = 5\n",
    "shuffle = True\n",
    "random_seed = 1234\n",
    "train_split = 0.8\n",
    "\n",
    "# 构建 PyTorch 中 Dataloader 对象\n",
    "flower_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((180, 180)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "flower_dataset = datasets.ImageFolder(\n",
    "    path_to_flower_dataset, transform=flower_transform\n",
    ")\n",
    "dataset_size = len(flower_dataset)\n",
    "# Define sampler\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "if shuffle:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "split = int(np.floor(train_split * dataset_size))\n",
    "train_indices, val_indices = indices[:split], indices[split:]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# Define databuilder\n",
    "train_loader = DataLoader(flower_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = DataLoader(flower_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "\n",
    "# 定义单机模型结构\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ConvRGBNet_torch(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 45 * 45, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 5),\n",
    "        )\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "# initialize\n",
    "model_torch = ConvRGBNet_torch()\n",
    "\n",
    "# Define the loss function\n",
    "loss_model_torch = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer_model_torch = torch.optim.SGD(params=model_torch.parameters(), lr=0.01)\n",
    "optimizer_model_torch.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step_per_epoch = len(train_loader)\n",
    "train_step_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f32befefe50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 180, 180])\n",
      "torch.Size([5])\n",
      "tensor([[[[0.6196, 0.6196, 0.6510,  ..., 0.2431, 0.2627, 0.2431],\n",
      "          [0.6118, 0.6275, 0.6667,  ..., 0.2118, 0.2275, 0.2275],\n",
      "          [0.6235, 0.6549, 0.6941,  ..., 0.1804, 0.1961, 0.2000],\n",
      "          ...,\n",
      "          [0.5451, 0.5451, 0.5412,  ..., 0.4314, 0.4353, 0.4353],\n",
      "          [0.5490, 0.5451, 0.5451,  ..., 0.4157, 0.4235, 0.4235],\n",
      "          [0.5490, 0.5451, 0.5490,  ..., 0.4078, 0.4157, 0.4157]],\n",
      "\n",
      "         [[0.6039, 0.6078, 0.6431,  ..., 0.3843, 0.4039, 0.3843],\n",
      "          [0.5961, 0.6157, 0.6588,  ..., 0.3451, 0.3608, 0.3490],\n",
      "          [0.6078, 0.6392, 0.6824,  ..., 0.2902, 0.3020, 0.3020],\n",
      "          ...,\n",
      "          [0.4706, 0.4706, 0.4667,  ..., 0.3647, 0.3647, 0.3608],\n",
      "          [0.4667, 0.4667, 0.4667,  ..., 0.3569, 0.3647, 0.3647],\n",
      "          [0.4667, 0.4627, 0.4667,  ..., 0.3569, 0.3647, 0.3686]],\n",
      "\n",
      "         [[0.6627, 0.6627, 0.6980,  ..., 0.1137, 0.1333, 0.1176],\n",
      "          [0.6549, 0.6745, 0.7176,  ..., 0.1059, 0.1216, 0.1137],\n",
      "          [0.6667, 0.7020, 0.7529,  ..., 0.0941, 0.1059, 0.1137],\n",
      "          ...,\n",
      "          [0.4941, 0.4941, 0.4902,  ..., 0.3176, 0.3255, 0.3294],\n",
      "          [0.4941, 0.4902, 0.4941,  ..., 0.3294, 0.3373, 0.3412],\n",
      "          [0.4941, 0.4902, 0.4941,  ..., 0.3333, 0.3412, 0.3451]]],\n",
      "\n",
      "\n",
      "        [[[0.0667, 0.0745, 0.0902,  ..., 0.3176, 0.2471, 0.2039],\n",
      "          [0.0667, 0.0745, 0.0902,  ..., 0.3373, 0.2627, 0.2275],\n",
      "          [0.0549, 0.0549, 0.0784,  ..., 0.2667, 0.1922, 0.1804],\n",
      "          ...,\n",
      "          [0.0118, 0.0157, 0.0235,  ..., 0.1020, 0.1020, 0.0980],\n",
      "          [0.0039, 0.0118, 0.0078,  ..., 0.0980, 0.0902, 0.0863],\n",
      "          [0.0000, 0.0118, 0.0078,  ..., 0.0980, 0.0824, 0.0745]],\n",
      "\n",
      "         [[0.1059, 0.1137, 0.1333,  ..., 0.3725, 0.3020, 0.2588],\n",
      "          [0.1020, 0.1098, 0.1333,  ..., 0.3843, 0.3098, 0.2706],\n",
      "          [0.0902, 0.0941, 0.1216,  ..., 0.3098, 0.2431, 0.2235],\n",
      "          ...,\n",
      "          [0.0510, 0.0471, 0.0627,  ..., 0.1608, 0.1608, 0.1569],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.1569, 0.1529, 0.1529],\n",
      "          [0.0471, 0.0588, 0.0510,  ..., 0.1569, 0.1451, 0.1412]],\n",
      "\n",
      "         [[0.0745, 0.0863, 0.1098,  ..., 0.0118, 0.0275, 0.0118],\n",
      "          [0.0784, 0.0902, 0.1137,  ..., 0.0275, 0.0235, 0.0196],\n",
      "          [0.0706, 0.0745, 0.1020,  ..., 0.0196, 0.0039, 0.0235],\n",
      "          ...,\n",
      "          [0.0353, 0.0353, 0.0510,  ..., 0.1882, 0.1882, 0.1843],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.1843, 0.1804, 0.1804],\n",
      "          [0.0314, 0.0431, 0.0353,  ..., 0.1843, 0.1725, 0.1686]]],\n",
      "\n",
      "\n",
      "        [[[0.8941, 0.8863, 0.8941,  ..., 0.9961, 1.0000, 1.0000],\n",
      "          [0.8980, 0.8941, 0.9020,  ..., 0.9922, 0.9961, 0.9961],\n",
      "          [0.8902, 0.9020, 0.9098,  ..., 0.9961, 1.0000, 0.9961],\n",
      "          ...,\n",
      "          [0.9765, 0.9686, 0.9608,  ..., 0.9529, 0.9529, 0.9490],\n",
      "          [0.9804, 0.9686, 0.9608,  ..., 0.9608, 0.9569, 0.9529],\n",
      "          [0.9725, 0.9647, 0.9608,  ..., 0.9608, 0.9569, 0.9569]],\n",
      "\n",
      "         [[0.8078, 0.7961, 0.8078,  ..., 0.9412, 0.9412, 0.9412],\n",
      "          [0.8118, 0.8039, 0.8157,  ..., 0.9333, 0.9373, 0.9412],\n",
      "          [0.7961, 0.8039, 0.8157,  ..., 0.9333, 0.9294, 0.9333],\n",
      "          ...,\n",
      "          [0.8784, 0.8745, 0.8667,  ..., 0.8667, 0.8627, 0.8549],\n",
      "          [0.8824, 0.8706, 0.8667,  ..., 0.8706, 0.8667, 0.8627],\n",
      "          [0.8706, 0.8627, 0.8627,  ..., 0.8667, 0.8627, 0.8627]],\n",
      "\n",
      "         [[0.0039, 0.0078, 0.0039,  ..., 0.1176, 0.1412, 0.1373],\n",
      "          [0.0039, 0.0118, 0.0039,  ..., 0.1176, 0.1333, 0.1176],\n",
      "          [0.0000, 0.0039, 0.0078,  ..., 0.1137, 0.1137, 0.0863],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0000, 0.0039,  ..., 0.0039, 0.0039, 0.0078],\n",
      "          [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0078]]],\n",
      "\n",
      "\n",
      "        [[[0.1373, 0.2039, 0.3059,  ..., 0.0863, 0.0980, 0.0863],\n",
      "          [0.1373, 0.2078, 0.2941,  ..., 0.0863, 0.0980, 0.1020],\n",
      "          [0.1098, 0.1686, 0.2588,  ..., 0.0863, 0.0980, 0.1059],\n",
      "          ...,\n",
      "          [0.2118, 0.2314, 0.1725,  ..., 0.8196, 0.8196, 0.8235],\n",
      "          [0.2275, 0.2039, 0.1686,  ..., 0.8118, 0.8118, 0.8196],\n",
      "          [0.2039, 0.2392, 0.1725,  ..., 0.8118, 0.8118, 0.8039]],\n",
      "\n",
      "         [[0.1529, 0.2157, 0.3098,  ..., 0.1020, 0.1137, 0.1373],\n",
      "          [0.1647, 0.2275, 0.3098,  ..., 0.1098, 0.1216, 0.1608],\n",
      "          [0.1490, 0.2078, 0.2980,  ..., 0.1216, 0.1333, 0.1647],\n",
      "          ...,\n",
      "          [0.2667, 0.3020, 0.2549,  ..., 0.8667, 0.8667, 0.8745],\n",
      "          [0.3098, 0.2824, 0.2510,  ..., 0.8588, 0.8588, 0.8667],\n",
      "          [0.3020, 0.3373, 0.2627,  ..., 0.8588, 0.8588, 0.8588]],\n",
      "\n",
      "         [[0.0667, 0.1137, 0.1804,  ..., 0.0353, 0.0471, 0.0549],\n",
      "          [0.0667, 0.1137, 0.1765,  ..., 0.0392, 0.0510, 0.0510],\n",
      "          [0.0353, 0.0745, 0.1490,  ..., 0.0392, 0.0510, 0.0431],\n",
      "          ...,\n",
      "          [0.1373, 0.0706, 0.0235,  ..., 0.9529, 0.9569, 0.9529],\n",
      "          [0.0706, 0.0627, 0.0706,  ..., 0.9529, 0.9529, 0.9569],\n",
      "          [0.0235, 0.0627, 0.0549,  ..., 0.9529, 0.9569, 0.9569]]],\n",
      "\n",
      "\n",
      "        [[[0.2000, 0.1961, 0.2157,  ..., 0.1098, 0.1255, 0.1569],\n",
      "          [0.2078, 0.1922, 0.2000,  ..., 0.0980, 0.1137, 0.1412],\n",
      "          [0.2157, 0.1922, 0.1882,  ..., 0.0824, 0.1020, 0.1333],\n",
      "          ...,\n",
      "          [0.2549, 0.2627, 0.2784,  ..., 0.2745, 0.2863, 0.2902],\n",
      "          [0.2549, 0.3294, 0.2863,  ..., 0.2745, 0.3922, 0.3333],\n",
      "          [0.2471, 0.2745, 0.3137,  ..., 0.3059, 0.4588, 0.3765]],\n",
      "\n",
      "         [[0.3059, 0.2941, 0.2706,  ..., 0.1843, 0.2118, 0.2314],\n",
      "          [0.3059, 0.2980, 0.2745,  ..., 0.1765, 0.2039, 0.2235],\n",
      "          [0.3098, 0.3020, 0.2784,  ..., 0.1608, 0.1882, 0.2157],\n",
      "          ...,\n",
      "          [0.4000, 0.3647, 0.3804,  ..., 0.3843, 0.3451, 0.3843],\n",
      "          [0.4000, 0.4275, 0.3843,  ..., 0.3569, 0.4510, 0.4314],\n",
      "          [0.4157, 0.4039, 0.4157,  ..., 0.3529, 0.5255, 0.4706]],\n",
      "\n",
      "         [[0.0392, 0.0353, 0.0431,  ..., 0.0784, 0.0863, 0.1176],\n",
      "          [0.0392, 0.0353, 0.0392,  ..., 0.0745, 0.0863, 0.1098],\n",
      "          [0.0392, 0.0353, 0.0392,  ..., 0.0706, 0.0824, 0.1098],\n",
      "          ...,\n",
      "          [0.1333, 0.2275, 0.2235,  ..., 0.1373, 0.1647, 0.1294],\n",
      "          [0.1569, 0.3020, 0.2353,  ..., 0.1451, 0.2863, 0.1765],\n",
      "          [0.1686, 0.2157, 0.2627,  ..., 0.1412, 0.3490, 0.2118]]]])\n",
      "tensor([3, 2, 1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# 获取一个批次的数据\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# 查看图像和标签的形状\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# 查看第一个批次的图像和标签内容\n",
    "print(images)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 PyTorch 的隐语联邦学习模型迁移\n",
    "基于 PyTorch 从单机模型到联邦学习模型，主要包含以下步骤：\n",
    "- 添加联邦学习中的参与方\n",
    "- 修改数据集的处理逻辑\n",
    "- 修改模型的继承类\n",
    "- 根据需要决定是否对 metric 、 optimizer 和 loss fuction 进行包装，并使用包装后的函数\n",
    "\n",
    "接下来，我们将结合实际代码具体讲解这些步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 环境设置\n",
    "添加联邦学习中的参与方，并对各个参与方进行初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 20:27:07,100\tINFO worker.py:1540 -- Connecting to existing Ray cluster at address: ecm-02:6379...\n",
      "2024-08-13 20:27:07,109\tINFO worker.py:1724 -- Connected to Ray cluster.\n",
      "2024-08-13 20:27:07.133 INFO api.py:233 [bob] -- [Anonymous_job] Started rayfed with {'CLUSTER_ADDRESSES': {'alice': 'ecm-01:16307', 'bob': '0.0.0.0:16307'}, 'CURRENT_PARTY_NAME': 'bob', 'TLS_CONFIG': {'ca_cert': '/home/beng003/certificate/alice_ca.crt', 'cert': '/home/beng003/certificate/bob_server_cert.crt', 'key': '/home/beng003/certificate/bob_server_key.key'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of SecretFlow: 1.8.0b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 20:27:08.137 INFO barriers.py:284 [bob] -- [Anonymous_job] Succeeded to create receiver proxy actor.\n",
      "\u001b[36m(ReceiverProxyActor pid=335916)\u001b[0m 2024-08-13 20:27:08.132 INFO grpc_proxy.py:359 [bob] -- [Anonymous_job] ReceiverProxy binding port 16307, options: (('grpc.enable_retries', 1), ('grpc.so_reuseport', 0), ('grpc.max_send_message_length', 524288000), ('grpc.max_receive_message_length', 524288000), ('grpc.service_config', '{\"methodConfig\": [{\"name\": [{\"service\": \"GrpcService\"}], \"retryPolicy\": {\"maxAttempts\": 5, \"initialBackoff\": \"5s\", \"maxBackoff\": \"30s\", \"backoffMultiplier\": 2, \"retryableStatusCodes\": [\"UNAVAILABLE\"]}}]}'))...\n",
      "\u001b[36m(ReceiverProxyActor pid=335916)\u001b[0m 2024-08-13 20:27:08.136 INFO grpc_proxy.py:379 [bob] -- [Anonymous_job] Successfully start Grpc service with credentials.\n",
      "2024-08-13 20:27:09.088 INFO barriers.py:333 [bob] -- [Anonymous_job] SenderProxyActor has successfully created.\n",
      "2024-08-13 20:27:09.090 INFO barriers.py:520 [bob] -- [Anonymous_job] Try ping ['alice'] at 0 attemp, up to 3600 attemps.\n",
      "2024-08-13 20:27:12.094 INFO barriers.py:520 [bob] -- [Anonymous_job] Try ping ['alice'] at 1 attemp, up to 3600 attemps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:27:15,357 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4209774592; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:27:25,368 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4205883392; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:27:35,375 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4209680384; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:27:45,383 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4209717248; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:27:55,390 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208603136; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:28:05,397 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4209557504; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:28:15,405 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4205686784; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:28:25,412 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4209442816; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:28:35,419 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4205613056; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:28:45,429 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208402432; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:28:55,437 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4209397760; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:29:05,444 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4205498368; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:29:15,451 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208259072; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:29:25,458 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4209233920; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:29:35,465 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208189440; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:29:45,473 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4209205248; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:29:55,480 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4205338624; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:30:05,487 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208082944; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:30:15,494 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4209070080; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:30:25,502 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207992832; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:30:35,509 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4209004544; capacity: 105089261568. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorPYUFedAvgW pid=336904)\u001b[0m {'train-loss': 0.885633647441864, 'train_multiclassaccuracy': tensor(0.6500), 'train_multiclassprecision': tensor(0.6500), 'val_eval_multiclassaccuracy': tensor(0.), 'val_eval_multiclassprecision': tensor(0.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:37:25,812 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207427584; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:37:35,819 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4203675648; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:37:45,837 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207370240; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:37:55,851 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4203499520; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:38:05,861 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206243840; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:38:15,868 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207210496; capacity: 105089261568. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "# bob.py\n",
    "import secretflow as sf\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print(\"The version of SecretFlow: {}\".format(sf.__version__))\n",
    "\n",
    "# In case you have a running secretflow runtime already.\n",
    "sf.shutdown()\n",
    "\n",
    "pyu_port = 16307\n",
    "spu_port = 11666\n",
    "\n",
    "cluster_config = {\n",
    "    \"parties\": {\n",
    "        \"alice\": {\n",
    "            # replace with alice's real address.\n",
    "            \"address\": \"ecm-01:\" + str(pyu_port),\n",
    "            \"listen_addr\": \"0.0.0.0:\" + str(pyu_port),\n",
    "        },\n",
    "        \"bob\": {\n",
    "            # replace with bob's real address.\n",
    "            \"address\": \"ecm-02:\" + str(pyu_port),\n",
    "            \"listen_addr\": \"0.0.0.0:\" + str(pyu_port),\n",
    "        },\n",
    "    },\n",
    "    \"self_party\": \"bob\",\n",
    "}\n",
    "\n",
    "tls_config = {\n",
    "    \"ca_cert\": \"/home/beng003/certificate/alice_ca.crt\",\n",
    "    \"cert\": \"/home/beng003/certificate/bob_server_cert.crt\",\n",
    "    \"key\": \"/home/beng003/certificate/bob_server_key.key\",\n",
    "}\n",
    "\n",
    "\n",
    "sf.init(address=\"ecm-02:6379\", cluster_config=cluster_config, tls_config=tls_config)\n",
    "alice, bob = sf.PYU(\"alice\"), sf.PYU(\"bob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 封装单机模式下的数据处理逻辑\n",
    "同样地，在联邦学习中我们也需要对数据进行预处理，使之符合模型的输入，所以参考在[SecretFlow 中使用自定义 DataBuilder (Torch)构建 dataset builder](https://www.secretflow.org.cn/docs/secretflow/latest/zh-Hans/tutorial/CustomDataLoaderTorch)，我们选择文件夹路径作为参数，并且封装单机模式下的数据处理逻辑，最后返回 (data_set，steps_per_epoch)的结果，封装代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_builder(\n",
    "    batch_size=5,\n",
    "    train_split=0.8,\n",
    "    shuffle=True,\n",
    "    random_seed=1234,\n",
    "):\n",
    "    def dataset_builder(x, stage=\"train\"):\n",
    "        \"\"\" \"\"\"\n",
    "        ######################################单机模型数据读取代码#########################################\n",
    "        import math\n",
    "\n",
    "        import numpy as np\n",
    "        from torch.utils.data import DataLoader\n",
    "        from torch.utils.data.sampler import SubsetRandomSampler\n",
    "        from torchvision import datasets, transforms\n",
    "\n",
    "        # Define dataset\n",
    "\n",
    "        flower_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((180, 180)),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        flower_dataset = datasets.ImageFolder(x, transform=flower_transform)\n",
    "        dataset_size = len(flower_dataset)\n",
    "        # Define sampler\n",
    "\n",
    "        indices = list(range(dataset_size))\n",
    "        if shuffle:\n",
    "            np.random.seed(random_seed)\n",
    "            np.random.shuffle(indices)\n",
    "        split = int(np.floor(train_split * dataset_size))\n",
    "        train_indices, val_indices = indices[:split], indices[split:]\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "        # Define databuilder\n",
    "        train_loader = DataLoader(\n",
    "            flower_dataset, batch_size=batch_size, sampler=train_sampler\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            flower_dataset, batch_size=batch_size, sampler=valid_sampler\n",
    "        )\n",
    "        #############################################################################################\n",
    "        # Return\n",
    "        if stage == \"train\":\n",
    "            train_step_per_epoch = len(train_loader)\n",
    "\n",
    "            return train_loader, train_step_per_epoch\n",
    "        elif stage == \"eval\":\n",
    "            eval_step_per_epoch = len(valid_loader)\n",
    "            return valid_loader, eval_step_per_epoch\n",
    "\n",
    "    return dataset_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建 dataset_builder_dict\n",
    "\n",
    "我们通过 dataset_builder_dict 为各个参与方传入封装数据处理逻辑的 create_dataset_builder 函数的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset dict\n",
    "data_builder_dict = {\n",
    "    alice: create_dataset_builder(\n",
    "        batch_size=5,\n",
    "        train_split=0.8,\n",
    "        shuffle=False,\n",
    "        random_seed=1234,\n",
    "    ),\n",
    "    bob: create_dataset_builder(\n",
    "        batch_size=5,\n",
    "        train_split=0.8,\n",
    "        shuffle=False,\n",
    "        random_seed=1234,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在隐语的框架下定义基于 PyTorch 的模型架构\n",
    "参考 PyTorch 单机模式下的模型，我们在隐语的框架下定义同样结构的模型。\n",
    "\n",
    "我们只需修改继承类将 **torch.nn.Module** 改为 **secretflow.ml.nn.core.torch.BaseModule**，就可以完成模型架构的定义。\n",
    "\n",
    "从迁移过程可以看出，将单机模型在隐语框架下进行定义所进行的代码改动非常小，整体迁移非常方便，充分展现了隐语框架的易用性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.ml.nn.core.torch import BaseModule\n",
    "\n",
    "\n",
    "######################################单机模型代码#########################################\n",
    "class ConvRGBNet(BaseModule):  # 只有这里有变化，其他和单机模型定义保持一致\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 45 * 45, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 5),\n",
    "        )\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建TorchModel\n",
    "`TorchModel`是我们在隐语中定义的一个概念，层级概念上对应`keras model`。目的是将将用户定义的`模型`，`loss函数`,`optimizer`,`metrics`封装在一起，用与后续FLModel在启动后统一多后端逻辑。  \n",
    "其中需要注意的是，我们的loss_fn，optim_fn，metrics都需要通过一个wrapper封装成一个偏函数传入进去，在后面会有详细的解析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 20:27:46.045 INFO proxy.py:187 [bob] -- [Anonymous_job] Create proxy actor <class 'secretflow.device.proxy.Actor_Masker'> with party alice.\n",
      "2024-08-13 20:27:46.046 INFO proxy.py:187 [bob] -- [Anonymous_job] Create proxy actor <class 'secretflow.device.proxy.Actor_Masker'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "from secretflow.ml.nn import FLModel\n",
    "from secretflow.security.aggregation import SecureAggregator\n",
    "from torch import nn, optim\n",
    "from torchmetrics import Accuracy, Precision\n",
    "from secretflow.ml.nn.core.torch import TorchModel, metric_wrapper, optim_wrapper\n",
    "\n",
    "\n",
    "device_list = [alice, bob]\n",
    "aggregator = SecureAggregator(alice, [alice, bob])\n",
    "# prepare model\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "input_shape = (180, 180, 3)\n",
    "# torch model\n",
    "\n",
    "optim_fn = optim_wrapper(optim.Adam, lr=1e-3)\n",
    "model_def = TorchModel(\n",
    "    model_fn=ConvRGBNet,\n",
    "    loss_fn=nn.CrossEntropyLoss,\n",
    "    optim_fn=optim_fn,\n",
    "    metrics=[\n",
    "        metric_wrapper(\n",
    "            Accuracy, task=\"multiclass\", num_classes=num_classes, average='micro'\n",
    "        ),\n",
    "        metric_wrapper(\n",
    "            Precision, task=\"multiclass\", num_classes=num_classes, average='micro'\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义FLModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 20:27:53.221 INFO proxy.py:187 [bob] -- [Anonymous_job] Create proxy actor <class 'abc.ActorPYUFedAvgW'> with party alice.\n",
      "2024-08-13 20:27:53.223 INFO proxy.py:187 [bob] -- [Anonymous_job] Create proxy actor <class 'abc.ActorPYUFedAvgW'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "fed_model = FLModel(\n",
    "    device_list=device_list,\n",
    "    model=model_def,\n",
    "    aggregator=aggregator,\n",
    "    backend=\"torch\",  # backend support ['tensorflow', 'torch']\n",
    "    strategy=\"fed_avg_w\",\n",
    "    random_seed=1234,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 20:27:58.160 INFO fl_model.py:396 [bob] -- [Anonymous_job] FL Train Params: {'x': {PYURuntime(alice): '/home/beng003/python_project/sf-test/data/datasets/flower_photos', PYURuntime(bob): '/home/beng003/python_project/sf-test/data/datasets/flower_photos'}, 'y': None, 'batch_size': 5, 'batch_sampling_rate': None, 'epochs': 5, 'verbose': 1, 'callbacks': None, 'validation_data': {PYURuntime(alice): '/home/beng003/python_project/sf-test/data/datasets/flower_photos', PYURuntime(bob): '/home/beng003/python_project/sf-test/data/datasets/flower_photos'}, 'shuffle': False, 'class_weight': None, 'sample_weight': None, 'validation_freq': 1, 'aggregate_freq': 2, 'label_decoder': None, 'max_batch_size': 20000, 'prefetch_buffer_size': None, 'sampler_method': 'batch', 'random_seed': 1234, 'dp_spent_step_freq': 1, 'audit_log_dir': None, 'dataset_builder': {PYURuntime(alice): <function create_dataset_builder.<locals>.dataset_builder at 0x7fe4d14b3640>, PYURuntime(bob): <function create_dataset_builder.<locals>.dataset_builder at 0x7fe39c5a24d0>}, 'wait_steps': 100, 'self': <secretflow.ml.nn.fl.fl_model.FLModel object at 0x7fe39c5e0c70>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beng003/anaconda/envs/sf/lib/python3.10/site-packages/secretflow/ml/nn/metrics.py:59: UserWarning: Please pay attention to local metrics, global only do naive aggregation.\n",
      "  warnings.warn(\n",
      "2024-08-13 20:30:37.843189: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Train Processing: :  50%|█████     | 2/4 [02:40<02:40, 80.07s/it, {'multiclassaccuracy': 0.2, 'multiclassprecision': 0.2, 'val_multiclassaccuracy': 0.0, 'val_multiclassprecision': 0.0}]\n",
      "Train Processing: :   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorPYUFedAvgW pid=336904)\u001b[0m {'train-loss': 1.5570476055145264, 'train_multiclassaccuracy': tensor(0.2000), 'train_multiclassprecision': tensor(0.2000), 'val_eval_multiclassaccuracy': tensor(0.), 'val_eval_multiclassprecision': tensor(0.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:30:45,517 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4205146112; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:30:55,524 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207919104; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:31:05,532 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208889856; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:31:15,540 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207816704; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:31:25,546 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208783360; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:31:35,554 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4204929024; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:31:45,562 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207718400; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:31:55,569 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208713728; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:32:05,576 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4204904448; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:32:15,583 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208599040; capacity: 105089261568. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :  50%|█████     | 2/4 [01:40<01:40, 50.16s/it, {'multiclassaccuracy': 0.4, 'multiclassprecision': 0.4, 'val_multiclassaccuracy': 0.0, 'val_multiclassprecision': 0.0}]\n",
      "Train Processing: :   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorPYUFedAvgW pid=336904)\u001b[0m {'train-loss': 1.4086425304412842, 'train_multiclassaccuracy': tensor(0.4000), 'train_multiclassprecision': tensor(0.4000), 'val_eval_multiclassaccuracy': tensor(0.), 'val_eval_multiclassprecision': tensor(0.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:32:25,593 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4204707840; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:32:35,600 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207497216; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:32:45,607 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208513024; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:32:55,615 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4204638208; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:33:05,622 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208418816; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:33:15,629 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4204552192; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:33:25,637 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207288320; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:33:35,644 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208304128; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:33:45,651 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4204453888; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:33:55,658 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208230400; capacity: 105089261568. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :  50%|█████     | 2/4 [01:39<01:39, 49.90s/it, {'multiclassaccuracy': 0.6, 'multiclassprecision': 0.6, 'val_multiclassaccuracy': 0.0, 'val_multiclassprecision': 0.0}]\n",
      "Train Processing: :   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorPYUFedAvgW pid=336904)\u001b[0m {'train-loss': 1.2114331722259521, 'train_multiclassaccuracy': tensor(0.6000), 'train_multiclassprecision': tensor(0.6000), 'val_eval_multiclassaccuracy': tensor(0.), 'val_eval_multiclassprecision': tensor(0.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:34:05,666 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4204363776; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:34:15,673 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207120384; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:34:25,680 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208099328; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:34:35,687 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4204249088; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:34:45,694 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208041984; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:34:55,701 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4208029696; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:35:05,707 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206940160; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:35:15,714 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207919104; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:35:25,722 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4204044288; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:35:35,729 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206829568; capacity: 105089261568. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :  50%|█████     | 2/4 [01:40<01:40, 50.06s/it, {'multiclassaccuracy': 0.7, 'multiclassprecision': 0.7, 'val_multiclassaccuracy': 0.0, 'val_multiclassprecision': 0.0}]\n",
      "Train Processing: :   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorPYUFedAvgW pid=336904)\u001b[0m {'train-loss': 1.0411512851715088, 'train_multiclassaccuracy': tensor(0.7000), 'train_multiclassprecision': tensor(0.7000), 'val_eval_multiclassaccuracy': tensor(0.), 'val_eval_multiclassprecision': tensor(0.)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:35:45,736 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207837184; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:35:55,744 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206784512; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:36:05,751 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207751168; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:36:15,758 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4203868160; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:36:25,766 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206624768; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:36:35,773 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207636480; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:36:45,780 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206592000; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:36:55,786 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207583232; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:37:05,794 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4203692032; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:37:15,801 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206440448; capacity: 105089261568. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :  50%|█████     | 2/4 [01:40<01:40, 50.01s/it, {'multiclassaccuracy': 0.65, 'multiclassprecision': 0.65, 'val_multiclassaccuracy': 0.0, 'val_multiclassprecision': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    alice: path_to_flower_dataset,\n",
    "    bob: path_to_flower_dataset,\n",
    "}\n",
    "history = fed_model.fit(\n",
    "    data,\n",
    "    None,\n",
    "    validation_data=data,\n",
    "    epochs=5,\n",
    "    batch_size=5,\n",
    "    aggregate_freq=2,\n",
    "    sampler_method=\"batch\",\n",
    "    random_seed=1234,\n",
    "    dp_spent_step_freq=1,\n",
    "    dataset_builder=data_builder_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_history': {'multiclassaccuracy': [0.2, 0.4, 0.6, 0.7, 0.65],\n",
       "  'multiclassprecision': [0.2, 0.4, 0.6, 0.7, 0.65],\n",
       "  'val_multiclassaccuracy': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'val_multiclassprecision': [0.0, 0.0, 0.0, 0.0, 0.0]},\n",
       " 'local_history': {'alice_train-loss': [1.5570476055145264,\n",
       "   1.4086425304412842,\n",
       "   1.2114331722259521,\n",
       "   1.0411512851715088,\n",
       "   0.885633647441864],\n",
       "  'alice_train_multiclassaccuracy': [tensor(0.2000),\n",
       "   tensor(0.4000),\n",
       "   tensor(0.6000),\n",
       "   tensor(0.7000),\n",
       "   tensor(0.6500)],\n",
       "  'alice_train_multiclassprecision': [tensor(0.2000),\n",
       "   tensor(0.4000),\n",
       "   tensor(0.6000),\n",
       "   tensor(0.7000),\n",
       "   tensor(0.6500)],\n",
       "  'alice_val_eval_multiclassaccuracy': [tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.)],\n",
       "  'alice_val_eval_multiclassprecision': [tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.)],\n",
       "  'bob_train-loss': [1.5570476055145264,\n",
       "   1.4086425304412842,\n",
       "   1.2114331722259521,\n",
       "   1.0411512851715088,\n",
       "   0.885633647441864],\n",
       "  'bob_train_multiclassaccuracy': [tensor(0.2000),\n",
       "   tensor(0.4000),\n",
       "   tensor(0.6000),\n",
       "   tensor(0.7000),\n",
       "   tensor(0.6500)],\n",
       "  'bob_train_multiclassprecision': [tensor(0.2000),\n",
       "   tensor(0.4000),\n",
       "   tensor(0.6000),\n",
       "   tensor(0.7000),\n",
       "   tensor(0.6500)],\n",
       "  'bob_val_eval_multiclassaccuracy': [tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.)],\n",
       "  'bob_val_eval_multiclassprecision': [tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.)]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到FLModel对象之后，就可以用这个对象进行`fit`,`evaluate`,`predict`等操作了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why need wraps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将单机模型下的 optimizer 包装（wrap）\n",
    "对 optimizer 进行包装的原因：我们需要使用 optimizer 在训练过程中自动地调整模型参数，以使模型在给定的训练数据上达到最佳的性能表现。同样地，联邦学习也可以通过 optimizer 实现模型更好的性能。但由于隐语的设计机制需要把相关模块通过序列化到具体的机器上才会执行，因此在优化器需要指定参数时，需要做一次封装。\n",
    "\n",
    "通过`optim_wrapper`进行优化器（optimizer）的包装，并且通过追根溯源，我们可以看到。\n",
    "```python\n",
    "from secretflow.ml.nn.core.torch import optim_wrapper\n",
    "```\n",
    "[source code](https://github.com/secretflow/secretflow/blob/main/secretflow/ml/nn/core/torch/utils.py#L23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_wrapper(func, *args, **kwargs):\n",
    "\n",
    "    def wrapped_func(params):\n",
    "        return func(params, *args, **kwargs)\n",
    "\n",
    "    return wrapped_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到函数实际上都是通过传入一个需要包装的函数名称，位置参数和关键字参数对函数完成包装，通过关键字参数确保了指定的参数赋值，然后返回包装好的函数。\n",
    "因此\n",
    "```python\n",
    "optim_fn = optim_wrapper(optim.Adam, lr=1e-2)\n",
    "```\n",
    "实际上相当于调用\n",
    "```python\n",
    "optim.Adam(lr=1e-2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将单机模型下的 metric 包装（wrap）\n",
    "对 metric 进行包装的原因:metric 在机器学习和深度学习中用于衡量模型的性能和表现，它们是评估模型在训练、验证或测试数据上的效果的标准。同样地，我们也希望使用 metric 衡量联邦学习模型的性能和表现。但由于隐语的设计机制同 PyTorch 有些差异，因此在衡量指标需要指定参数时，需要做一次封装来保证两者的一致性。\n",
    "\n",
    "通过`metric_wrapper`进行衡量指标（metric）的包装，并且通过追根溯源，我们可以看到\n",
    "```python\n",
    "from secretflow.ml.nn.core.torch import metric_wrapper\n",
    "```\n",
    "[source code](https://github.com/secretflow/secretflow/blob/main/secretflow/ml/nn/core/torch/utils.py#L23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_wrapper(func, *args, **kwargs):\n",
    "    def wrapped_func():\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapped_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到函数实际上是通过传入一个需要包装的函数名称，位置参数和关键字参数对函数完成包装，通过关键字参数确保了指定的参数赋值，然后返回包装好的函数；与优化器包装类似\n",
    "因此\n",
    "```python\n",
    "metric_wrapper(Accuracy, task=\"multiclass\", num_classes=10, average='micro')\n",
    "```\n",
    "实际上相当于调用\n",
    "```python\n",
    "Accuracy(task=\"multiclass\", num_classes=10, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将单机模型下的 loss function 包装（wrap）\n",
    "参考 `optim_wrapper` 和 `metric_wrapper` 的定义方式，自定义 `loss_function_wrapper`对损失函数（loss function）进行包装。\n",
    "\n",
    "如果模型使用损失函数的默认参数，则不需要使用包装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_wrapper(func, *args, **kwargs):\n",
    "    def wrapped_func():\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapped_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得益于隐语的封装，并且根据前述的包装原理可知，我们实际上需要通过包装完成一个参数具体化的函数，所以在这里 `nn.CrossEntropyLoss` 是需要包装的函数，并且其参数取值，就是需要传入的参数值。因为在其默认参数取值设置中，  `reduction='mean'` , 此处我们试着将其修改为 ` reduction='sum'`。包装损失函数只需要写成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_wrapper = loss_function_wrapper(nn.CrossEntropyLoss, reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对单机模型使用包装（wrap）后的优化器（optimizer）、衡量指标（metric）和损失函数（loss function）\n",
    "在隐语框架下，使用者可以根据需要选择是否对优化器（optimizer）、衡量指标（metric）和损失函数（loss function）进行包装，从而更好地训练联邦学习模型，充分发挥隐语框架的灵活性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "基于 PyTorch 从单机模型到联邦学习模型，主要需要添加或修改以下几部分\n",
    "- 添加联邦学习中的参与方\n",
    "- 修改数据集的处理逻辑\n",
    "- 修改模型的继承类\n",
    "- 根据需要决定是否对 metric 、 optimizer 和 loss fuction 进行包装，并使用包装后的函数\n",
    "\n",
    "得益于隐语的封装，使用者不需要自己完成模型定义等代码的编写，只需要调用 Secretflow 中的函数，即可便捷完成模型的定义和使用等操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 TensorFlow 的迁移教程\n",
    "### 模型在 TensorFlow 下的单机模型实现\n",
    "首先我们给出单机模式下，基于 TensorFlow 定义和训练神经网络模型的过程。对于数据，我们将其加载成 TensorFlow 的 dataset 对象\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 files belonging to 5 classes.\n",
      "Using 20 files for training.\n",
      "Using 5 files for validation.\n",
      "-------Start training-------\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 1.7442 - accuracy: 0.2000 - val_loss: 1.5286 - val_accuracy: 0.6000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.2989 - accuracy: 0.5500 - val_loss: 1.4937 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.9715 - accuracy: 0.7000 - val_loss: 1.4600 - val_accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.6000 - accuracy: 0.8500 - val_loss: 1.9802 - val_accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.3277 - accuracy: 0.8500 - val_loss: 1.5714 - val_accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.2519 - accuracy: 0.9500 - val_loss: 1.5647 - val_accuracy: 0.2000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.1580 - accuracy: 0.9500 - val_loss: 3.9757 - val_accuracy: 0.2000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.1216 - accuracy: 1.0000 - val_loss: 0.9846 - val_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.0904 - accuracy: 0.9500 - val_loss: 2.1207 - val_accuracy: 0.2000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.1800 - accuracy: 0.9500 - val_loss: 2.6655 - val_accuracy: 0.2000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "batch_size = 5\n",
    "# In this example, we use the TensorFlow interface for development.\n",
    "data_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_to_flower_dataset,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "train_set = data_set[0]\n",
    "test_set = data_set[1]\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# Create model\n",
    "num_classes = 5\n",
    "input_shape = (180, 180, 3)\n",
    "total_epochs = 10\n",
    "\n",
    "model_tensorflow = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        tf.keras.layers.Rescaling(1.0 / 255),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "model_tensorflow.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Model training and validation\n",
    "print('-------Start training-------')\n",
    "history = model_tensorflow.fit(\n",
    "    train_set,\n",
    "    validation_data=test_set,\n",
    "    batch_size=batch_size,\n",
    "    epochs=total_epochs,\n",
    "    verbose=True,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 TensorFlow 的隐语联邦学习模型迁移\n",
    "#### 概述 \n",
    "基于 TensorFlow 从单机模型到联邦学习模型，主要包含以下步骤：\n",
    "- 添加联邦学习中的参与方\n",
    "- 修改数据集的处理逻辑\n",
    "- 进行模型的封装\n",
    "\n",
    "接下来，我们将结合实际代码具体讲解这些步骤。\n",
    "### 环境设置\n",
    "添加联邦学习中的参与方，并初始化各个参与方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of SecretFlow: 1.8.0b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 20:38:18.435 INFO api.py:342 [bob] -- [Anonymous_job] Shutdowning rayfed intendedly...\n",
      "2024-08-13 20:38:18.437 INFO api.py:356 [bob] -- [Anonymous_job] Wait for data sending.\n",
      "2024-08-13 20:38:18.438 INFO message_queue.py:72 [bob] -- [Anonymous_job] Notify message polling thread[DataSendingQueueThread] to exit.\n",
      "2024-08-13 20:38:18.440 INFO message_queue.py:102 [bob] -- [Anonymous_job] The message polling thread[DataSendingQueueThread] was exited.\n",
      "2024-08-13 20:38:18.441 INFO message_queue.py:72 [bob] -- [Anonymous_job] Notify message polling thread[ErrorSendingQueueThread] to exit.\n",
      "2024-08-13 20:38:18.491 INFO message_queue.py:102 [bob] -- [Anonymous_job] The message polling thread[ErrorSendingQueueThread] was exited.\n",
      "2024-08-13 20:38:18.492 INFO barriers.py:469 [bob] -- [Anonymous_job] Stop sender proxy actor...\n",
      "2024-08-13 20:38:18.496 INFO barriers.py:473 [bob] -- [Anonymous_job] Sender proxy actor stoped.\n",
      "2024-08-13 20:38:18.496 INFO api.py:384 [bob] -- [Anonymous_job] Shutdowned rayfed.\n",
      "2024-08-13 20:38:19,192\tINFO worker.py:1540 -- Connecting to existing Ray cluster at address: ecm-02:6379...\n",
      "2024-08-13 20:38:19,201\tINFO worker.py:1724 -- Connected to Ray cluster.\n",
      "2024-08-13 20:38:19.219 INFO api.py:233 [bob] -- [Anonymous_job] Started rayfed with {'CLUSTER_ADDRESSES': {'alice': 'ecm-01:16307', 'bob': '0.0.0.0:16307'}, 'CURRENT_PARTY_NAME': 'bob', 'TLS_CONFIG': {'ca_cert': '/home/beng003/certificate/alice_ca.crt', 'cert': '/home/beng003/certificate/bob_server_cert.crt', 'key': '/home/beng003/certificate/bob_server_key.key'}}\n",
      "2024-08-13 20:38:20.229 INFO barriers.py:284 [bob] -- [Anonymous_job] Succeeded to create receiver proxy actor.\n",
      "\u001b[36m(ReceiverProxyActor pid=348594)\u001b[0m 2024-08-13 20:38:20.224 INFO grpc_proxy.py:359 [bob] -- [Anonymous_job] ReceiverProxy binding port 16307, options: (('grpc.enable_retries', 1), ('grpc.so_reuseport', 0), ('grpc.max_send_message_length', 524288000), ('grpc.max_receive_message_length', 524288000), ('grpc.service_config', '{\"methodConfig\": [{\"name\": [{\"service\": \"GrpcService\"}], \"retryPolicy\": {\"maxAttempts\": 5, \"initialBackoff\": \"5s\", \"maxBackoff\": \"30s\", \"backoffMultiplier\": 2, \"retryableStatusCodes\": [\"UNAVAILABLE\"]}}]}'))...\n",
      "\u001b[36m(ReceiverProxyActor pid=348594)\u001b[0m 2024-08-13 20:38:20.228 INFO grpc_proxy.py:379 [bob] -- [Anonymous_job] Successfully start Grpc service with credentials.\n",
      "2024-08-13 20:38:21.175 INFO barriers.py:333 [bob] -- [Anonymous_job] SenderProxyActor has successfully created.\n",
      "2024-08-13 20:38:21.176 INFO barriers.py:520 [bob] -- [Anonymous_job] Try ping ['alice'] at 0 attemp, up to 3600 attemps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:38:25,876 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206067712; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:38:35,883 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4207079424; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:38:45,891 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4203225088; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[36m(pid=349295)\u001b[0m 2024-08-13 20:38:53.044216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:38:55,902 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4205957120; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:39:05,914 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206923776; capacity: 105089261568. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:40:55,997 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4202708992; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:41:06,004 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206493696; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:41:16,011 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4202614784; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:41:26,018 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4205371392; capacity: 105089261568. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "# bob.py\n",
    "import secretflow as sf\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print(\"The version of SecretFlow: {}\".format(sf.__version__))\n",
    "\n",
    "# In case you have a running secretflow runtime already.\n",
    "sf.shutdown()\n",
    "\n",
    "pyu_port = 16307\n",
    "spu_port = 11666\n",
    "\n",
    "cluster_config = {\n",
    "    \"parties\": {\n",
    "        \"alice\": {\n",
    "            # replace with alice's real address.\n",
    "            \"address\": \"ecm-01:\" + str(pyu_port),\n",
    "            \"listen_addr\": \"0.0.0.0:\" + str(pyu_port),\n",
    "        },\n",
    "        \"bob\": {\n",
    "            # replace with bob's real address.\n",
    "            \"address\": \"ecm-02:\" + str(pyu_port),\n",
    "            \"listen_addr\": \"0.0.0.0:\" + str(pyu_port),\n",
    "        },\n",
    "    },\n",
    "    \"self_party\": \"bob\",\n",
    "}\n",
    "\n",
    "tls_config = {\n",
    "    \"ca_cert\": \"/home/beng003/certificate/alice_ca.crt\",\n",
    "    \"cert\": \"/home/beng003/certificate/bob_server_cert.crt\",\n",
    "    \"key\": \"/home/beng003/certificate/bob_server_key.key\",\n",
    "}\n",
    "\n",
    "\n",
    "sf.init(address=\"ecm-02:6379\", cluster_config=cluster_config, tls_config=tls_config)\n",
    "alice, bob = sf.PYU(\"alice\"), sf.PYU(\"bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_builder(\n",
    "    batch_size=5,\n",
    "):\n",
    "    def dataset_builder(folder_path, stage=\"train\"):\n",
    "        ############################单机模型代码#############################################\n",
    "        import math\n",
    "\n",
    "        import tensorflow as tf\n",
    "\n",
    "        img_height = 180\n",
    "        img_width = 180\n",
    "        data_set = tf.keras.utils.image_dataset_from_directory(\n",
    "            folder_path,\n",
    "            validation_split=0.2,\n",
    "            subset=\"both\",\n",
    "            seed=123,\n",
    "            image_size=(img_height, img_width),\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        ####################################################################################\n",
    "        if stage == \"train\":\n",
    "            train_dataset = data_set[0]\n",
    "            train_step_per_epoch = math.ceil(len(data_set[0].file_paths) / batch_size)\n",
    "            return train_dataset, train_step_per_epoch\n",
    "        elif stage == \"eval\":\n",
    "            eval_dataset = data_set[1]\n",
    "            eval_step_per_epoch = math.ceil(len(data_set[1].file_paths) / batch_size)\n",
    "            return eval_dataset, eval_step_per_epoch\n",
    "\n",
    "    return dataset_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建 dataset_builder_dict\n",
    "我们通过 dataset_builder_dict 为各个参与方传入封装数据处理逻辑的 create_dataset_builder 函数的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_builder_dict = {\n",
    "    alice: create_dataset_builder(\n",
    "        batch_size=5,\n",
    "    ),\n",
    "    bob: create_dataset_builder(\n",
    "        batch_size=5,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在隐语的框架下定义基于 TensorFlow 的模型架构\n",
    "参考 TensorFlow 单机模式下的模型，我们在隐语的框架下定义同样结构的模型。\n",
    "\n",
    "如前所述，我们需要使用 optimizer 在训练过程中自动地调整模型参数，以使模型在给定的训练数据上达到最佳的性能表现；使用 metric 在机器学习和深度学习中用于衡量模型的性能和表现；使用损失函数监督神经网络的训练。同样地，联邦学习也可以通过使用优化器（optimizer）、衡量指标（metric）和损失函数（loss function） 实现模型更好的性能。在隐语框架下，优化器（optimizer）、衡量指标（metric）和损失函数（loss function）的使用方法和 TensorFlow 中的使用方法一致，也同样通过模型的 compile 函数实现。\n",
    "\n",
    "从迁移过程可以看出，代码修改幅度非常小，整体迁移过程非常方便，充分展现了隐语框架的易用性和便捷性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_flower_model(input_shape, num_classes, name='model'):\n",
    "    def create_model():\n",
    "        ##########################单机模型代码##################################\n",
    "        from tensorflow import keras\n",
    "\n",
    "        # Create model\n",
    "\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                tf.keras.layers.Rescaling(1.0 / 255),\n",
    "                tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(),\n",
    "                tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(),\n",
    "                tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(128, activation='relu'),\n",
    "                tf.keras.layers.Dense(num_classes),\n",
    "            ]\n",
    "        )\n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer='adam',\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "        ##########################单机模型代码##################################\n",
    "\n",
    "    return create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.ml.nn import FLModel\n",
    "from secretflow.security.aggregation import SecureAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 20:38:46.445 INFO proxy.py:187 [bob] -- [Anonymous_job] Create proxy actor <class 'secretflow.device.proxy.Actor_Masker'> with party alice.\n",
      "2024-08-13 20:38:46.446 INFO proxy.py:187 [bob] -- [Anonymous_job] Create proxy actor <class 'secretflow.device.proxy.Actor_Masker'> with party bob.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 20:38:50.311 INFO proxy.py:187 [bob] -- [Anonymous_job] Create proxy actor <class 'secretflow.device.proxy.ActorPYUFedAvgW'> with party alice.\n",
      "2024-08-13 20:38:50.313 INFO proxy.py:187 [bob] -- [Anonymous_job] Create proxy actor <class 'secretflow.device.proxy.ActorPYUFedAvgW'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "device_list = [alice, bob]\n",
    "aggregator = SecureAggregator(alice, [alice, bob])\n",
    "\n",
    "# prepare model\n",
    "num_classes = 5\n",
    "input_shape = (180, 180, 3)\n",
    "\n",
    "# keras model\n",
    "model = create_conv_flower_model(input_shape, num_classes)\n",
    "\n",
    "\n",
    "fed_model = FLModel(\n",
    "    device_list=device_list,\n",
    "    model=model,\n",
    "    aggregator=aggregator,\n",
    "    backend=\"tensorflow\",\n",
    "    strategy=\"fed_avg_w\",\n",
    "    random_seed=1234,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练和验证模型\n",
    "传入参与方的数据集路径，进行模型的训练和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 20:39:08.338 INFO fl_model.py:396 [bob] -- [Anonymous_job] FL Train Params: {'x': {PYURuntime(alice): '/home/beng003/python_project/sf-test/data/datasets/flower_photos', PYURuntime(bob): '/home/beng003/python_project/sf-test/data/datasets/flower_photos'}, 'y': None, 'batch_size': 5, 'batch_sampling_rate': None, 'epochs': 2, 'verbose': 1, 'callbacks': None, 'validation_data': {PYURuntime(alice): '/home/beng003/python_project/sf-test/data/datasets/flower_photos', PYURuntime(bob): '/home/beng003/python_project/sf-test/data/datasets/flower_photos'}, 'shuffle': False, 'class_weight': None, 'sample_weight': None, 'validation_freq': 1, 'aggregate_freq': 2, 'label_decoder': None, 'max_batch_size': 20000, 'prefetch_buffer_size': None, 'sampler_method': 'batch', 'random_seed': 1234, 'dp_spent_step_freq': 1, 'audit_log_dir': None, 'dataset_builder': {PYURuntime(alice): <function create_dataset_builder.<locals>.dataset_builder at 0x7fe39c5a1870>, PYURuntime(bob): <function create_dataset_builder.<locals>.dataset_builder at 0x7fe39c5a1bd0>}, 'wait_steps': 100, 'self': <secretflow.ml.nn.fl.fl_model.FLModel object at 0x7fe1dc2776d0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorPYUFedAvgW pid=349295)\u001b[0m Found 25 files belonging to 5 classes.\n",
      "\u001b[36m(ActorPYUFedAvgW pid=349295)\u001b[0m Using 20 files for training.\n",
      "\u001b[36m(ActorPYUFedAvgW pid=349295)\u001b[0m Using 5 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:39:15,921 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4203036672; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:39:25,928 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206841856; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:39:35,936 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4202991616; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:39:45,945 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4205776896; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:39:55,952 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206780416; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:40:05,960 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4202975232; capacity: 105089261568. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorPYUFedAvgW pid=349295)\u001b[0m Found 25 files belonging to 5 classes.\n",
      "\u001b[36m(ActorPYUFedAvgW pid=349295)\u001b[0m Using 20 files for training.\n",
      "\u001b[36m(ActorPYUFedAvgW pid=349295)\u001b[0m Using 5 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :  50%|█████     | 2/4 [01:02<01:02, 31.20s/it, {'loss': 1.9371605, 'accuracy': 0.15, 'val_loss': 1.5980835, 'val_accuracy': 0.4}]\n",
      "Train Processing: :   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:40:15,967 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206669824; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:40:25,975 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4202786816; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:40:35,982 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4205568000; capacity: 105089261568. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-08-13 20:40:45,989 E 265544 265570] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-08-13_19-19-00_433060_265452 is over 95% full, available space: 4206583808; capacity: 105089261568. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :  50%|█████     | 2/4 [00:39<00:39, 19.55s/it, {'loss': 1.5927668, 'accuracy': 0.28, 'val_loss': 1.5951079, 'val_accuracy': 0.2}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorPYUFedAvgW pid=349295)\u001b[0m Found 25 files belonging to 5 classes.\n",
      "\u001b[36m(ActorPYUFedAvgW pid=349295)\u001b[0m Using 20 files for training.\n",
      "\u001b[36m(ActorPYUFedAvgW pid=349295)\u001b[0m Using 5 files for validation.\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    alice: path_to_flower_dataset,\n",
    "    bob: path_to_flower_dataset,\n",
    "}\n",
    "history = fed_model.fit(\n",
    "    data,\n",
    "    None,\n",
    "    validation_data=data,\n",
    "    epochs=2,\n",
    "    batch_size=5,\n",
    "    aggregate_freq=2,\n",
    "    sampler_method=\"batch\",\n",
    "    random_seed=1234,\n",
    "    dp_spent_step_freq=1,\n",
    "    dataset_builder=data_builder_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_history': {'loss': [1.9371605, 1.5927668],\n",
       "  'accuracy': [0.15, 0.28],\n",
       "  'val_loss': [1.5980835, 1.5951079],\n",
       "  'val_accuracy': [0.4, 0.2]},\n",
       " 'local_history': {'alice_loss': [1.9371605, 1.5927668],\n",
       "  'alice_accuracy': [0.15, 0.28],\n",
       "  'alice_val_loss': [1.5980835, 1.5951079],\n",
       "  'alice_val_accuracy': [0.4, 0.2],\n",
       "  'bob_loss': [1.9371605, 1.5927668],\n",
       "  'bob_accuracy': [0.15, 0.28],\n",
       "  'bob_val_loss': [1.5980835, 1.5951079],\n",
       "  'bob_val_accuracy': [0.4, 0.2]}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小结\n",
    "基于 TensorFlow 从单机模型到联邦学习模型，主要需要添加或修改以下几部分\n",
    "- 添加联邦学习中的参与方\n",
    "- 修改数据集的处理逻辑\n",
    "- 进行模型的封装\n",
    "\n",
    "得益于隐语的封装，使用者不需要自己进行大量的代码编写，只需要调用 Secretflow 中的函数，即可便捷完成模型的定义和使用等操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "本教程说明了使用者能够在 SecretFlow 隐语的框架下，体会到和单机模式下，使用 PyTorch 或 Tensorflow 编程几乎一致的联邦学习模型使用体验。充分展现了隐语框架具有易用性和便捷性等优点。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
