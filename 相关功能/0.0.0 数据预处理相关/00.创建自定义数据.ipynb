{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`secretflow.utils.simulation.data.dataframe.create_df` 是一个用于创建联邦数据框的函数，支持根据数据源和数据分区方案生成 `HDataFrame` 或 `VDataFrame`。它允许将数据按行或按列分割，并支持多种数据分区方法。\n",
    "\n",
    "### 函数签名\n",
    "\n",
    "```\n",
    "python复制代码create_df(\n",
    "    source: str | DataFrame | Callable,\n",
    "    parts: List[PYU] | Dict[PYU, float | tuple],\n",
    "    axis: int = 0,\n",
    "    shuffle: bool = False,\n",
    "    random_state: int | None = None,\n",
    "    aggregator: Aggregator | None = None,\n",
    "    comparator: Comparator | None = None,\n",
    "    split_method: SPLIT_METHOD = SPLIT_METHOD.IID,\n",
    "    label_column: str | None = None,\n",
    "    **kwargs\n",
    ") → HDataFrame | VDataFrame\n",
    "```\n",
    "\n",
    "### 参数\n",
    "\n",
    "- **source**: 数据源，可以是文件路径、`pandas.DataFrame` 对象，或一个返回 `pandas.DataFrame` 的 callable 对象。\n",
    "\n",
    "- **parts**: 数据分区方案。\n",
    "\n",
    "  - 如果是 `List[PYU]` 类型，则数据将尽可能均匀地分配给每个 PYU。\n",
    "\n",
    "  - 如果是 \n",
    "\n",
    "    ```\n",
    "    Dict[PYU, float | tuple]\n",
    "    ```\n",
    "\n",
    "     类型，PYU 的值决定了数据分配的比例或范围。具体可以是：\n",
    "\n",
    "    - `float`：每个 PYU 分配的数据比例。\n",
    "    - `tuple`：一个区间（左闭右开），用于指定数据分配的范围。\n",
    "\n",
    "- **axis**: 可选，分割的轴。\n",
    "\n",
    "  - `0`：按行分割，返回水平分区的联邦数据框（`HDataFrame`）。\n",
    "  - `1`：按列分割，返回垂直分区的联邦数据框（`VDataFrame`）。\n",
    "\n",
    "- **shuffle**: 可选，是否在分割数据之前对数据进行洗牌。\n",
    "\n",
    "- **random_state**: 可选，用于洗牌的随机种子。\n",
    "\n",
    "- **aggregator**: 可选，仅在 `axis=0` 时使用，指定用于水平分区的聚合器。\n",
    "\n",
    "- **comparator**: 可选，仅在 `axis=0` 时使用，指定用于水平分区的比较器。\n",
    "\n",
    "- **split_method**: 可选，指定数据分区的方法。默认为 `SPLIT_METHOD.IID`（独立同分布）。其他方法包括：\n",
    "\n",
    "  - `SPLIT_METHOD.DIRICHLET`：Dirichlet 分区方法。\n",
    "  - `SPLIT_METHOD.LABEL_SKEW`：标签偏斜分区方法。\n",
    "\n",
    "- **label_column**: 可选，指定用于标签偏斜的标签列名。\n",
    "\n",
    "- **kwargs**: 可选，其他分割方法的参数，如 `num_classes`（用于 Dirichlet 分区）或 `alpha`（用于 Dirichlet 分区）等。\n",
    "\n",
    "### 返回值\n",
    "\n",
    "- 如果 `axis=0`，则返回 `HDataFrame`（水平分区的联邦数据框）。\n",
    "- 如果 `axis=1`，则返回 `VDataFrame`（垂直分区的联邦数据框）。"
   ],
   "id": "c26fffeaa8938d94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T12:40:09.526485Z",
     "start_time": "2024-07-20T12:40:05.510074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import secretflow as sf\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print('The version of SecretFlow: {}'.format(sf.__version__))\n",
    "\n",
    "# In case you have a running secretflow runtime already.\n",
    "sf.shutdown()\n",
    "\n",
    "sf.init(['alice', 'bob'], address='local')\n",
    "alice = sf.PYU('alice')\n",
    "bob = sf.PYU('bob')\n",
    "spu = sf.SPU(sf.utils.testing.cluster_def(parties=['alice', 'bob']))"
   ],
   "id": "ff94a20642f12450",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of SecretFlow: 1.8.0b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beng003/anaconda/envs/sf/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _posixsubprocess.fork_exec(\n",
      "2024-07-20 20:40:08,776\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T12:40:10.891988Z",
     "start_time": "2024-07-20T12:40:10.887123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from secretflow.utils.simulation.data.dataframe import create_df\n",
    "from secretflow.utils.simulation.data import SPLIT_METHOD\n",
    "\n",
    "# 示例数据\n",
    "df = pd.DataFrame({'f1': [1, 2, 3, 4], 'f3': [11, 12, 13, 14]})"
   ],
   "id": "3185e7a6834a9c5e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T12:40:14.929999Z",
     "start_time": "2024-07-20T12:40:14.293062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建水平分区的 HDataFrame，数据均匀分配\n",
    "hdf = create_df(df, [alice, bob], axis=0)\n",
    "\n",
    "# 创建垂直分区的 VDataFrame，指定每个 PYU 的数据比例\n",
    "vdf = create_df(df, {alice: 0.3, bob: 0.7}, axis=1)\n",
    "\n",
    "# 创建水平分区的 HDataFrame，指定每个 PYU 的数据范围\n",
    "hdf = create_df(df, {alice: (0, 1), bob: (1, 4)})"
   ],
   "id": "1ffe9dce88781e12",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.device.proxy.ActorPartitionAgent'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.device.proxy.ActorPartitionAgent'> with party bob.\n",
      "INFO:root:Create proxy actor <class 'secretflow.device.proxy.ActorPartitionAgent'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.device.proxy.ActorPartitionAgent'> with party bob.\n",
      "INFO:root:Create proxy actor <class 'secretflow.device.proxy.ActorPartitionAgent'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.device.proxy.ActorPartitionAgent'> with party bob.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T12:40:17.441182Z",
     "start_time": "2024-07-20T12:40:17.350104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用 Dirichlet 分区方法创建水平分区的 HDataFrame\n",
    "hdf = create_df(df, [alice, bob], axis=0, split_method=SPLIT_METHOD.DIRICHLET, num_classes=2, alpha=1000)"
   ],
   "id": "487b1e4a2d201dda",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda/envs/sf/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/anaconda/envs/sf/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/anaconda/envs/sf/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: None",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 使用 Dirichlet 分区方法创建水平分区的 HDataFrame\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m hdf \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43malice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbob\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mSPLIT_METHOD\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDIRICHLET\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda/envs/sf/lib/python3.10/site-packages/secretflow/utils/simulation/data/dataframe.py:126\u001B[0m, in \u001B[0;36mcreate_df\u001B[0;34m(source, parts, axis, shuffle, random_state, aggregator, comparator, split_method, label_column, **kwargs)\u001B[0m\n\u001B[1;32m    124\u001B[0m num_classes \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_classes\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    125\u001B[0m alpha \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malpha\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m10000\u001B[39m)\n\u001B[0;32m--> 126\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlabel_column\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m num_classes \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdirichlet partition must supply num_classes\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    129\u001B[0m indexes \u001B[38;5;241m=\u001B[39m dirichlet_partition(\n\u001B[1;32m    130\u001B[0m     parts\u001B[38;5;241m=\u001B[39mparts,\n\u001B[1;32m    131\u001B[0m     targets\u001B[38;5;241m=\u001B[39mtarget,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    134\u001B[0m     random_seed\u001B[38;5;241m=\u001B[39mrandom_state,\n\u001B[1;32m    135\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda/envs/sf/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/anaconda/envs/sf/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: None"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:39:42.808243Z",
     "start_time": "2024-07-20T07:39:42.781475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用标签偏斜分区方法创建水平分区的 HDataFrame\n",
    "hdf = create_df(df, [alice, bob], axis=0, split_method=SPLIT_METHOD.LABEL_SKEW, label_column='f1',skew_ratio=0.5)"
   ],
   "id": "17fa0cb5de7be199",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "LABEL_SKEW",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 使用标签偏斜分区方法创建水平分区的 HDataFrame\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m hdf \u001B[38;5;241m=\u001B[39m create_df(df, [alice, bob], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, split_method\u001B[38;5;241m=\u001B[39m\u001B[43mSPLIT_METHOD\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLABEL_SKEW\u001B[49m, label_column\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m'\u001B[39m,skew_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda/envs/sf/lib/python3.10/enum.py:437\u001B[0m, in \u001B[0;36mEnumMeta.__getattr__\u001B[0;34m(cls, name)\u001B[0m\n\u001B[1;32m    435\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_member_map_[name]\n\u001B[1;32m    436\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[0;32m--> 437\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(name) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: LABEL_SKEW"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
